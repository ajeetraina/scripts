<!DOCTYPE html>
<html>
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <link href='https://fonts.googleapis.com/css?family=Architects+Daughter' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen" />
    <link rel="stylesheet" type="text/css" href="stylesheets/pygment_trac.css" media="screen" />
    <link rel="stylesheet" type="text/css" href="stylesheets/print.css" media="print" />

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <title>Hadoop by ajeetraina</title>
  </head>

  <body>
    <header>
      <div class="inner">
        <h1>Hadoop</h1>
        <h2>Setting up Single Node Hadoop Cluster through auitomated script</h2>
        <a href="https://github.com/ajeetraina/scripts" class="button"><small>View project on</small>GitHub</a>
      </div>
    </header>

    <div id="content-wrapper">
      <div class="inner clearfix">
        <section id="main-content">
          <p>1.Create a user called Hadoop as shown below:</p>

<p>$ adduser hadoop</p>

<p>$ passwd hadoop</p>

<p>For this series, we will keep hadoop/ hadoop as credential.</p>

<p>Once logged in as Hadoop user, one can verify the userid with the below command:</p>

<p>$id</p>

<p>It will show hadoop as uid and gid which means you are good to go.</p>

<p>We are going to use hadoop-1.0.3 version for initial setup.</p>

<p>Download <a href="http://archive.apache.org/dist/hadoop/core/hadoop-1.0.3/hadoop-1.0.3.tar.gz">http://archive.apache.org/dist/hadoop/core/hadoop-1.0.3/hadoop-1.0.3.tar.gz</a> and place it under /usr/local/ directory.</p>

<p>Go to /usr/local/ directory.</p>

<p>$sudo tar xvzf hadoop-1.0.3.tar.gz</p>

<p>$sudo mv hadoop-1.0.3 hadoop</p>

<p>HADOOP CONFIGURATION FILES:</p>

<p>$cd /usr/local/hadoop</p>

<p>$cd conf</p>

<p>$vi core-site.xml</p>

<p></p>

<p>hadoop.tmp.dir</p>

<p>/app/hadoop/tmp</p>

<p>A base for other temporary directories.</p>

<p></p>

<p></p>

<p>fs.default.name</p>

<p>hdfs://localhost:54310</p>

<p>The name of the default file system. A URI whose</p>

<p>scheme and authority determine the FileSystem implementation. The</p>

<p>uri's scheme determines the config property (fs.SCHEME.impl) naming</p>

<p>the FileSystem implementation class. The uri's authority is used to</p>

<p>determine the host, port, etc. for a filesystem.</p>

<p></p>

<h1></h1>

<h1>
<a name="vi-mapred-sitexml" class="anchor" href="#vi-mapred-sitexml"><span class="octicon octicon-link"></span></a>vi mapred-site.xml</h1>

<p></p>

<p>mapred.job.tracker</p>

<p>localhost:54311</p>

<p>The host and port that the MapReduce job tracker runs</p>

<p>at. If "local", then jobs are run in-process as a single map</p>

<p>and reduce task.</p>

<p></p>

<p></p>

<h1></h1>

<h1>
<a name="vi-hdfs-sitexml" class="anchor" href="#vi-hdfs-sitexml"><span class="octicon octicon-link"></span></a>vi hdfs-site.xml</h1>

<p></p>

<p>dfs.replication</p>

<p>1</p>

<p>Default block replication.</p>

<p>The actual number of replications can be specified when the file is created.</p>

<p>The default is used if replication is not specified in create time.</p>

<p></p>

<p></p>

<h1></h1>

<p>This completes the configuration of Hadoop Configuration files.</p>

<p>Create the neccessary directory structure:</p>

<p>$ cd /usr/local</p>

<p>$ sudo tar xzf hadoop-1.0.3.tar.gz</p>

<p>$ sudo mv hadoop-1.0.3 hadoop</p>

<p>$ sudo chown -R hadoop:hadoop hadoop</p>

<h1></h1>

<p>$cd /usr/local/hadoop/conf</p>

<p>$sudo vi masters</p>

<p>Add this entry only as:</p>

<p>localhost</p>

<p>$sudo vi slaves</p>

<p>Add this entry only as:</p>

<p>localhost</p>

<h1></h1>

<p>Setting up JAVA Environment:</p>

<p>Ensure you are logged in as hadoop user.</p>

<p>$pwd</p>

<p>/home/hadoop</p>

<p>$vi .bashrc</p>

<p>export HADOOP_HOME=/usr/local/hadoop</p>

<p>export JAVA_HOME=/home/hadoop/software/java/jdk1.6.0_45</p>

<p>unalias fs &amp;&gt; /dev/null</p>

<p>alias fs="hadoop fs"</p>

<p>unalias hls &amp;&gt; /dev/null</p>

<p>alias hls="fs -ls"</p>

<p>export PATH=$PATH:$HADOOP_HOME/bin</p>

<p>save the file.</p>

<p>Ensure the following command is working:</p>

<p>$bash</p>

<p>$echo $JAVA_HOME</p>

<p>$echo $JAVA_HOME</p>

<p>Both should show the correct entry as shown in .bashrc</p>

<p>Open the file : /usr/local/hadoop/bin/hadoop-env.sh</p>

<p>Make a one line entry:</p>

<p>export JAVA_HOME=/home/hadoop/software/java/jdk1.6.0_45</p>

<p>save it.</p>

<p>Run bash command simply.</p>

<p>Formatting HDFS:</p>

<h1>
<a name="usrlocalhadoopbinhadoop-namenode--format" class="anchor" href="#usrlocalhadoopbinhadoop-namenode--format"><span class="octicon octicon-link"></span></a>/usr/local/hadoop/bin/hadoop namenode -format</h1>

<p>It will show like this:</p>

<p>10/05/08 16:59:56 INFO namenode.NameNode: STARTUP_MSG:</p>

<p>/************************************************************</p>

<p>STARTUP_MSG: Starting NameNode</p>

<p>STARTUP_MSG: host = ubuntu/127.0.1.1</p>

<p>STARTUP_MSG: args = [-format]</p>

<p>STARTUP_MSG: version = 0.20.2</p>

<p>STARTUP_MSG: build = <a href="https://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.20">https://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.20</a> -r 911707; compiled by 'chrisdo' on Fri Feb 19 08:07:34 UTC 2010</p>

<p>************************************************************/</p>

<p>10/05/08 16:59:56 INFO namenode.FSNamesystem: fsOwner=hduser,hadoop</p>

<p>10/05/08 16:59:56 INFO namenode.FSNamesystem: supergroup=supergroup</p>

<p>10/05/08 16:59:56 INFO namenode.FSNamesystem: isPermissionEnabled=true</p>

<p>10/05/08 16:59:56 INFO common.Storage: Image file of size 96 saved in 0 seconds.</p>

<p>10/05/08 16:59:57 INFO common.Storage: Storage directory .../hadoop-hduser/dfs/name has been successfully formatted.</p>

<p>10/05/08 16:59:57 INFO namenode.NameNode: SHUTDOWN_MSG:</p>

<p>/************************************************************</p>

<p>SHUTDOWN_MSG: Shutting down NameNode at ubuntu/127.0.1.1</p>

<hr><h1></h1>

<p>Enable Passwordless SSH:</p>

<p>$ssh-keygen -t rsa -P ""</p>

<p>It will ask for something and say yes..</p>

<p>$cat /home/hadoop/.ssh/id_rsa.pub &gt;&gt; /home/hadoop/.ssh/authorized_keys</p>

<p>$ssh localhost</p>

<p>Now you can ssh to localhost machine itself without password.</p>

<h1></h1>

<p>Now lets start the complete Hadoop service through:</p>

<p>/usr/local/hadoop/bin/start-all.sh</p>

<p>It will start namenode and datanode on the same machine..</p>

<h1></h1>

<p>Now lets load the data into Hadoop Cluster.</p>

<p>$/usr/local/hadoop/bin/hadoop namenode -format</p>

<p>Esnure you start start-all.sh service before running the below command.</p>

<p>$sudo /usr/local/hadoop/bin/start-all.sh</p>

<p>Lets copy the data as shown below:</p>

<p>$cd /usr/local/hadoop</p>

<p>$sudo bin/hadoop dfs -copyFromLocal /home/hadoop/software/Downloads/1Record /user/hadoop/1</p>

<p>This successfully loads a file called 1 into your HDFS filesystem..</p>

<p>How to verify?</p>

<p>Run this command:</p>

<p>$cd /usr/local/hadoop</p>

<p>$sudo bin/hadoop dfs -ls /</p>

<p>It will show a new directory called /user being created.</p>

<p>Now Lets analyze the dataset:</p>

<p>$cd /usr/local/hadoop</p>

<p>$bin/hadoop jar hadoop-examples-1.0.3.jar wordcount /user/hadoop/1 /user/hduser/1-results</p>

<p>Now you can open http://:50030 to see the hadoop jobs</p>

<p>Ensure you open this link in VM itself as http://localhost:50030.</p>

<p>if networking works in between host and VM you can successfully open it on host itself.</p>
        </section>

        <aside id="sidebar">
          <a href="https://github.com/ajeetraina/scripts/zipball/master" class="button">
            <small>Download</small>
            .zip file
          </a>
          <a href="https://github.com/ajeetraina/scripts/tarball/master" class="button">
            <small>Download</small>
            .tar.gz file
          </a>

          <p class="repo-owner"><a href="https://github.com/ajeetraina/scripts"></a> is maintained by <a href="https://github.com/ajeetraina">ajeetraina</a>.</p>

          <p>This page was generated by <a href="pages.github.com">GitHub Pages</a> using the Architect theme by <a href="https://twitter.com/jasonlong">Jason Long</a>.</p>
        </aside>
      </div>
    </div>

  
  </body>
</html>